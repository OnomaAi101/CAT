{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAT Testing notebook\n",
    "\n",
    "## Environment setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onomaai/anaconda3/envs/mcc/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "import torch\n",
    "from diffusers import AutoPipelineForText2Image, DiffusionPipeline\n",
    "base_model = \"runwayml/stable-diffusion-v1-5\"\n",
    "seed = 42\n",
    "lora_path = \"/data7/OnomaAi101/CAT/results/cat_statue_20240201_new_prompts/checkpoint-500\"\n",
    "dreambooth_path = \"/data7/OnomaAi101/CAT/results/dreambooth/cat_statue_20240205/\"\n",
    "cat_path = \"/data7/OnomaAi101/CAT/results/cat/cat_statue_20240210/checkpoint-500\"\n",
    "prompt = \"a cat statue on a green field\"\n",
    "\n",
    "generator = torch.Generator(device=\"cuda\").manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanila Lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:  43%|████▎     | 3/7 [00:00<00:00,  5.65it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:02<00:00,  3.47it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 19.87it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: no \"view\" rule for type \"image/png\" passed its test case\n",
      "       (for more information, add \"--debug=1\" on the command line)\n"
     ]
    }
   ],
   "source": [
    "pipeline = AutoPipelineForText2Image.from_pretrained(base_model, torch_dtype=torch.float16).to(\"cuda\")\n",
    "#pipeline.load_lora_weights(lora_path, weight_name=\"pytorch_lora_weights.safetensors\")\n",
    "image = pipeline(prompt, generator = generator).images[0]\n",
    "#image.save(\"/data7/OnomaAi101/CAT/results/cat_statue_20240201_new_prompts/checkpoint-500/no lora_a cat statue on a green field_0.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dreambooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'use_auth_token': True} are not expected by StableDiffusionPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:03<00:00,  2.24it/s]\n",
      "100%|██████████| 50/50 [00:06<00:00,  7.83it/s]\n"
     ]
    }
   ],
   "source": [
    "pipeline = DiffusionPipeline.from_pretrained(dreambooth_path, use_auth_token=True).to(\"cuda\")\n",
    "image = pipeline(\"cat statue, <shs>, on a green field\", generator = generator).images[0]\n",
    "image.save(\"/data7/OnomaAi101/CAT/results/dreambooth/cat_statue_20240213/dreambooth_<shs>, on a green field_2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:10<00:00,  1.47s/it]\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.55it/s]\n"
     ]
    }
   ],
   "source": [
    "pipeline = AutoPipelineForText2Image.from_pretrained(base_model, torch_dtype=torch.float16).to(\"cuda\")\n",
    "#pipeline.load_lora_weights(cat_path, weight_name=\"pytorch_lora_weights.safetensors\")\n",
    "image = pipeline(prompt, generator = generator).images[0]\n",
    "image.save(f\"{cat_path}/no lora_a cat statue on a green field_0.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image similarity 0.9017925262451172\n",
      "Prompt similarity: 0.21938830614089966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21938830614089966"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.eval_utils import image_similarity, prompt_similarity\n",
    "\n",
    "image1 = \"/home/paneah/CAT/data/textual_inversion/clock/3.jpeg\"\n",
    "image2= \"/home/paneah/CAT/data/textual_inversion/clock/1.jpeg\"\n",
    "\n",
    "image_similarity(image1, image2)\n",
    "\n",
    "prompt = \"a dog statue lying on the carpet\"\n",
    "image = \"/home/paneah/CAT/data/textual_inversion/cat_statue/image1.jpeg\"\n",
    "\n",
    "prompt_similarity(prompt, image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
